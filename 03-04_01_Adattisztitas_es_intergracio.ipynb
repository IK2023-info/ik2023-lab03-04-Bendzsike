{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Adattisztítás és integráció.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adattisztítás és integráció"
      ],
      "metadata": {
        "id": "Z05V_ZhOqxws"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fry44sT_rAb"
      },
      "source": [
        "A valós adathalmazok gyakran zajosak, hiányosak, avagy éppen redundáns információt vagy duplikátum egyedeket tartalmaznak. Ezért a tudásfeltárás folyamatában az adattisztítás és adatintegrálással kezdődik.\n",
        "\n",
        "Az adattisztítás szerepe javítani az adatok minőségén azáltal, hogy kiszűri és eltávolítja az adatokban fellépő hibákat és inkonzisztenciákat.\n",
        "\n",
        "Az [adattisztítás](https://hu.wikipedia.org/wiki/Adattiszt%C3%ADtás) során:\n",
        "\"\n",
        "- felmérjük a hibákat\n",
        "\t- ellenőrizzük az adatfájl szerkezeti épségét\n",
        "\t- a zajt, felesleges információt tartalmazó mezőket javítjuk\n",
        "\t- felmérjük a hiányzó értékeket és amennyiben lehet ezeket pótoljuk\n",
        "\t- felmérjük az adatközlési és adatbeviteli hibákat\n",
        "\t\t- megvizsgáljuk az egyes változók eloszlását\n",
        "\t\t\t- az eloszlások szélein elhelyezkedő extrém értékeket ellenőrizzük\n",
        "\t\t\t- felmérjük, hogy az eloszlások megfelelnek-e az előzetes elvárásainknak, vannak-e nem várt sűrűsödések, ritkulások egyes értéktartományokban (például durva kerekítés vagy eltérő mértékegység használata az adatszolgáltatók egy részénél)\n",
        "\t\t-  megvizsgáljuk, hogy a változók közötti triviális összefüggések teljesülnek-e\n",
        "-  a hibásnak tűnő adatokat felülvizsgáljuk, javítjuk \n",
        "\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feladatok"
      ],
      "metadata": {
        "id": "a7og0Ax_quMN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2DOJGqVtF9I"
      },
      "source": [
        "1. Az `egyetemek.txt` fájlból szűrjük ki az államokat és azon belül a városokat, melyben egyetemek találhatóak. Ha vannak duplikátumok, helytelen adatok (pl. számokat tartalmazó államnév), ezeket javítsuk. Vizsgáljuk meg az egyetemek eloszlását államok szerint. Melyik államban van a legtöbb, legkevesebb egyetem?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_data/egyetemek.txt', 'r', encoding='utf-8') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "universities = {}\n",
        "\n",
        "for line in data:\n",
        "    line = line.strip()\n",
        "    if line:\n",
        "        try:\n",
        "            state, unis = line.split(\"[edit]\")\n",
        "            state = state.strip()\n",
        "            unis = unis.strip().strip(\"[]\")\n",
        "            uni_list = unis.split(\",\")\n",
        "            universities[state] = [uni.strip() for uni in uni_list]\n",
        "        except ValueError:\n",
        "            print(f\"Could not process line: {line}\")\n",
        "\n",
        "for line in data:\n",
        "    line = line.strip()\n",
        "    if line:\n",
        "        state, unis = line.split(\"[edit]\") if \"[edit]\" in line else (line, \"\")\n",
        "        state = state.strip()\n",
        "        unis = unis.strip().strip(\"[]\")\n",
        "        uni_list = unis.split(\",\")\n",
        "        universities[state] = [uni.strip() for uni in uni_list]\n",
        "\n",
        "counts = {state: len(unis) for state, unis in universities.items()}\n",
        "\n",
        "most_unis_state = max(counts, key=counts.get)\n",
        "least_unis_state = min(counts, key=counts.get)\n",
        "\n",
        "print(\"**********************************************************\")\n",
        "print(f\"Most Uni: {most_unis_state} ({counts[most_unis_state]} db)\")\n",
        "print(f\"Least Uni: {least_unis_state} ({counts[least_unis_state]} db)\")\n",
        "print(\"**********************************************************\")\n",
        "\n",
        "# print(universities)"
      ],
      "metadata": {
        "id": "vr4YVEsoqktV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Bővítsük ki az adatbázisunkat egy oszloppal, mely tartalmazza az államok rövidítését is (pl. Texas - TX, California - CA stb.).  [Forrás](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations)."
      ],
      "metadata": {
        "id": "BTHOaKHqqMsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_codes = pd.read_csv('/content/content/sample_data/shortNames.csv',names = ['State', 'Code'])\n",
        "df = df.merge(df_codes, on = 'State', how='left')"
      ],
      "metadata": {
        "id": "n8SFIlSkqlBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = df[['State','Code']].copy()\n",
        "d['szam'] = 1\n",
        "uniabs = d.groupby(['State']).sum()\n",
        "uniabs = uniabs.merge(df_codes, on = 'State', how='left')\n",
        "uniabs"
      ],
      "metadata": {
        "id": "sMnU5LOf-di0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Az adatbázist integráljuk a [List of states and territories of the United States by population](https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population) linken szereplő népszámlálási adatokkal és számoljuk ki államonként hány főre jut egy egyetemi város."
      ],
      "metadata": {
        "id": "ghSXt3L9qPgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pop = pd.read_csv('/content/sample_data/popular.csv',names = ['State', 'Popular'])"
      ],
      "metadata": {
        "id": "3AvsZZ6rqlim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = df[['State','Code']].copy()\n",
        "d['szam'] = 1\n",
        "by_state = d.groupby(['State'])\n",
        "by_state = by_state.sum()\n",
        "new_pop = by_state.merge(df_pop, on = 'State', how='left')\n",
        "new_pop = new_pop.merge(df_codes, on = 'State', how='left')\n",
        "new_pop['fo/egyet'] = new_pop['Popular']/new_pop['szam']\n",
        "new_pop.head()\n"
      ],
      "metadata": {
        "id": "Kj3VCGca-jUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Hasonlóan, a [List of U.S. states and territories by area](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area) linken szereplő területi adatok integrálásával, számoljuk ki államonként átlagban hány négyzetkilométerre jut egy egyetemi város."
      ],
      "metadata": {
        "id": "nLtpIoKEqTRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_area = pd.read_csv('/content/sample_data/area.csv',names = ['State', 'Area'])"
      ],
      "metadata": {
        "id": "fsQqL_1Vql91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = df[['State']].copy()\n",
        "d['szam'] = 1\n",
        "by_state = d.groupby(['State'])\n",
        "by_state = by_state.sum()\n",
        "area = by_state.merge(df_area, on = 'State', how='left')\n",
        "area = area.merge(df_codes, on = 'State', how='left')\n",
        "area['ter/egyet'] = area['Area']//area['szam']\n",
        "area.head()"
      ],
      "metadata": {
        "id": "1a9wgIYw_EOw",
        "outputId": "331dd8c2-38c6-477e-fda2-050d345e860a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bf9709085c4a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'State'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'szam'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mby_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'State'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mby_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'State'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. A [példa](https://datasciencechalktalk.com/2019/09/28/analyzing-u-s-exports-with-plotly/), a kivitelt, exportmennyiséget ábrázolja az Amerikai Egyesült Államok térképen, államonként lebontva ezt. Készítsünk hasonló ábrákat az egyetemek abszolút, lakoság és terület szerinti eloszlásáról is. Az ábrákat exportáljuk kép formájában.\n",
        "![](https://i.ibb.co/s1zdnLY/mapplot.png)\n",
        "\n",
        "Ábra 1. [Térképen való ábrázolás](https://plotly.com/python/maps/) Plotly segítségével. [Forrás](https://datasciencechalktalk.com/2019/09/28/analyzing-u-s-exports-with-plotly/)."
      ],
      "metadata": {
        "id": "_SNDj-RrqWGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data = go.Choropleth(\n",
        "    locations = area['Code'],\n",
        "    z = area['ter/egyet'],\n",
        "    locationmode = 'USA-states',\n",
        "    colorscale = 'Reds',\n",
        "))\n",
        "fig.update_layout(\n",
        "    title_text = '2011 US Area/University by State',\n",
        "    geo_scope = 'usa',\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "sKVmK4YkqnPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data = go.Choropleth(\n",
        "    locations = new_pop['Code'],\n",
        "    z = new_pop['fo/egyet'],\n",
        "    locationmode = 'USA-states',\n",
        "    colorscale = 'Reds',\n",
        "))\n",
        "fig.update_layout(\n",
        "    title_text = '2011 US Popular/University by State',\n",
        "    geo_scope = 'usa',\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KzUq2Yyn_XtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data = go.Choropleth(\n",
        "    locations = uniabs['Code'],\n",
        "    z = uniabs['szam'],\n",
        "    locationmode = 'USA-states',\n",
        "    colorscale = 'Reds',\n",
        "))\n",
        "fig.update_layout(\n",
        "    title_text = '2011 US Absalut University by State',\n",
        "    geo_scope = 'usa',\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KYmUTqVi_aRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Számoljuk ki, hány egyetem van városonként, majd összesítve államonként. Ehhez az `egyetemek.txt` fájlban miután megkapunk egy várost, az utána következő kerek zárójelek között megszámoljuk, hány vesszővel elválasztott karakterlánc található. \n",
        "Pl. a következő sorban:\t`Claremont (Claremont McKenna College, Pomona College, Harvey Mudd College, Scripps College, Pitzer College, Keck Graduate Institute, Claremont Graduate University)[5]` -> 6 vessző van a kerek zárójelek között, tehát 7 egyetem van a városban.    \n",
        "Melyik államban és melyik városban van a legtöbb egyetem?"
      ],
      "metadata": {
        "id": "pKZXgALRqard"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_town(item):\n",
        "  return item[:item.find('(') - 1]\n",
        "def clean_state(item):\n",
        "  return item[:item.find('[')]\n",
        "def what_univers(item):\n",
        "  return len(item[item.find('(') - 1:].split(','))\n",
        "\n",
        "df1['NumberUniv'] = df1.Town.apply(what_univers)\n",
        "df1['Town'] = df1.Town.apply(clean_town)\n",
        "df1['State'] = df1.State.apply(clean_state)\n",
        "df1"
      ],
      "metadata": {
        "id": "5tULBhUJqnzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "by_state = df1.groupby(['State'])\n",
        "maxi = by_state.NumberUniv.sum().max()\n",
        "mini = by_state.NumberUniv.sum().min()\n",
        "print(maxi,mini)\n",
        "\n",
        "by_town = df1.groupby(['Town'])\n",
        "maxi = by_town.NumberUniv.sum().max()\n",
        "mini = by_town.NumberUniv.sum().min()\n",
        "print(maxi,mini)"
      ],
      "metadata": {
        "id": "50ghUse__daY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}