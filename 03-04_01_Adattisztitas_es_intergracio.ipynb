{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Adattisztítás és integráció.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adattisztítás és integráció"
      ],
      "metadata": {
        "id": "Z05V_ZhOqxws"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fry44sT_rAb"
      },
      "source": [
        "A valós adathalmazok gyakran zajosak, hiányosak, avagy éppen redundáns információt vagy duplikátum egyedeket tartalmaznak. Ezért a tudásfeltárás folyamatában az adattisztítás és adatintegrálással kezdődik.\n",
        "\n",
        "Az adattisztítás szerepe javítani az adatok minőségén azáltal, hogy kiszűri és eltávolítja az adatokban fellépő hibákat és inkonzisztenciákat.\n",
        "\n",
        "Az [adattisztítás](https://hu.wikipedia.org/wiki/Adattiszt%C3%ADtás) során:\n",
        "\"\n",
        "- felmérjük a hibákat\n",
        "\t- ellenőrizzük az adatfájl szerkezeti épségét\n",
        "\t- a zajt, felesleges információt tartalmazó mezőket javítjuk\n",
        "\t- felmérjük a hiányzó értékeket és amennyiben lehet ezeket pótoljuk\n",
        "\t- felmérjük az adatközlési és adatbeviteli hibákat\n",
        "\t\t- megvizsgáljuk az egyes változók eloszlását\n",
        "\t\t\t- az eloszlások szélein elhelyezkedő extrém értékeket ellenőrizzük\n",
        "\t\t\t- felmérjük, hogy az eloszlások megfelelnek-e az előzetes elvárásainknak, vannak-e nem várt sűrűsödések, ritkulások egyes értéktartományokban (például durva kerekítés vagy eltérő mértékegység használata az adatszolgáltatók egy részénél)\n",
        "\t\t-  megvizsgáljuk, hogy a változók közötti triviális összefüggések teljesülnek-e\n",
        "-  a hibásnak tűnő adatokat felülvizsgáljuk, javítjuk \n",
        "\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feladatok"
      ],
      "metadata": {
        "id": "a7og0Ax_quMN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2DOJGqVtF9I"
      },
      "source": [
        "1. Az `egyetemek.txt` fájlból szűrjük ki az államokat és azon belül a városokat, melyben egyetemek találhatóak. Ha vannak duplikátumok, helytelen adatok (pl. számokat tartalmazó államnév), ezeket javítsuk. Vizsgáljuk meg az egyetemek eloszlását államok szerint. Melyik államban van a legtöbb, legkevesebb egyetem?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_data/egyetemek.txt', 'r', encoding='utf-8') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "universities = {}\n",
        "\n",
        "for line in data:\n",
        "    line = line.strip()\n",
        "    if line:\n",
        "        try:\n",
        "            state, unis = line.split(\"[edit]\")\n",
        "            state = state.strip()\n",
        "            unis = unis.strip().strip(\"[]\")\n",
        "            uni_list = unis.split(\",\")\n",
        "            universities[state] = [uni.strip() for uni in uni_list]\n",
        "        except ValueError:\n",
        "            print(f\"Could not process line: {line}\")\n",
        "\n",
        "for line in data:\n",
        "    line = line.strip()\n",
        "    if line:\n",
        "        state, unis = line.split(\"[edit]\") if \"[edit]\" in line else (line, \"\")\n",
        "        state = state.strip()\n",
        "        unis = unis.strip().strip(\"[]\")\n",
        "        uni_list = unis.split(\",\")\n",
        "        universities[state] = [uni.strip() for uni in uni_list]\n",
        "\n",
        "counts = {state: len(unis) for state, unis in universities.items()}\n",
        "\n",
        "most_unis_state = max(counts, key=counts.get)\n",
        "least_unis_state = min(counts, key=counts.get)\n",
        "\n",
        "print(\"**********************************************************\")\n",
        "print(f\"Most Uni: {most_unis_state} ({counts[most_unis_state]} db)\")\n",
        "print(f\"Least Uni: {least_unis_state} ({counts[least_unis_state]} db)\")\n",
        "print(\"**********************************************************\")\n",
        "\n",
        "# print(universities)"
      ],
      "metadata": {
        "id": "vr4YVEsoqktV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Bővítsük ki az adatbázisunkat egy oszloppal, mely tartalmazza az államok rövidítését is (pl. Texas - TX, California - CA stb.).  [Forrás](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations)."
      ],
      "metadata": {
        "id": "BTHOaKHqqMsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_codes = pd.read_csv('/content/content/sample_data/shortNames.csv',names = ['State', 'Code'])\n",
        "df = df.merge(df_codes, on = 'State', how='left')"
      ],
      "metadata": {
        "id": "n8SFIlSkqlBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = df[['State','Code']].copy()\n",
        "d['szam'] = 1\n",
        "uniabs = d.groupby(['State']).sum()\n",
        "uniabs = uniabs.merge(df_codes, on = 'State', how='left')\n",
        "uniabs"
      ],
      "metadata": {
        "id": "sMnU5LOf-di0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Az adatbázist integráljuk a [List of states and territories of the United States by population](https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population) linken szereplő népszámlálási adatokkal és számoljuk ki államonként hány főre jut egy egyetemi város."
      ],
      "metadata": {
        "id": "ghSXt3L9qPgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pop = pd.read_csv('/content/sample_data/popular.csv',names = ['State', 'Popular'])"
      ],
      "metadata": {
        "id": "3AvsZZ6rqlim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = df[['State','Code']].copy()\n",
        "d['szam'] = 1\n",
        "by_state = d.groupby(['State'])\n",
        "by_state = by_state.sum()\n",
        "new_pop = by_state.merge(df_pop, on = 'State', how='left')\n",
        "new_pop = new_pop.merge(df_codes, on = 'State', how='left')\n",
        "new_pop['fo/egyet'] = new_pop['Popular']/new_pop['szam']\n",
        "new_pop.head()\n"
      ],
      "metadata": {
        "id": "Kj3VCGca-jUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Hasonlóan, a [List of U.S. states and territories by area](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area) linken szereplő területi adatok integrálásával, számoljuk ki államonként átlagban hány négyzetkilométerre jut egy egyetemi város."
      ],
      "metadata": {
        "id": "nLtpIoKEqTRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Betöltjük az area táblázatot a wikipédiáról\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area\"\n",
        "html = urlopen(url)\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "table = soup.find_all(\"table\")[0]\n",
        "df_area = pd.read_html(str(table))[0]\n",
        "df_area.columns = df_area.columns.droplevel(0)\n",
        "\n",
        "# Betöltjük az egyetemek fájlt és számoljuk, hány egyetem van városonként\n",
        "with open(\"/content/sample_data/egyetemek.txt\", \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "city_university_counts = {}\n",
        "for line in lines:\n",
        "    city = line.split(\" (\")[0]\n",
        "    count = line.count(\",\") + 1\n",
        "    city_university_counts[city] = count\n",
        "\n",
        "# Összefésüljük az államokat és a városokat\n",
        "df_cities = pd.DataFrame.from_dict(city_university_counts, orient=\"index\", columns=[\"university_count\"])\n",
        "df_cities.index.name = \"City\"\n",
        "df_cities = df_cities.reset_index()\n",
        "df_cities[\"State\"] = df_cities[\"City\"].apply(lambda x: x.split(\", \")[-1])\n",
        "df_cities[\"City\"] = df_cities[\"City\"].apply(lambda x: x.split(\", \")[0])\n",
        "\n",
        "# print(df_area.columns)\n",
        "\n",
        "df_area = df_area.loc[:, ~df_area.columns.duplicated()]\n",
        "# print(df_area.columns)\n",
        "\n",
        "# Számoljuk ki az egyetemi városok összes területét az államonkénti összes területből kivonva az államon kívüli területeket\n",
        "df_area = df_area[df_area[\"Rank\"] != \"—\"]\n",
        "df_area[\"State\"] = df_area[\"State\"].str.replace(\"\\[.*\\]\", \"\", regex=True)\n",
        "df_area[\"sq mi\"] = df_area[\"sq mi\"].astype(str)\n",
        "df_area[\"sq mi\"] = df_area[\"sq mi\"].str.replace(\",\", \"\", regex=True).astype(float)\n",
        "df_area = df_area.groupby(\"State\").agg({\"sq mi\": sum})\n",
        "df_area = df_area.merge(df_cities, on=\"State\", how=\"outer\")\n",
        "df_area[\"University area per state\"] = df_area[\"sq mi\"] / df_area[\"university_count\"]\n",
        "\n",
        "# Kiírjuk az eredményt\n",
        "print(df_area[[\"State\", \"University area per state\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a9wgIYw_EOw",
        "outputId": "2d913442-05d5-4f8d-8058-ebe880c1c085"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 State  \\\n",
            "0                                 48 contiguous states   \n",
            "1                   50 states and District of Columbia   \n",
            "2                                              Alabama   \n",
            "3                                               Alaska   \n",
            "4    All 50 states, District of Columbia, and U.S. ...   \n",
            "..                                                 ...   \n",
            "581                                         Whitewater   \n",
            "582                                    Wyoming[edit]\\n   \n",
            "583                                            Laramie   \n",
            "584                                     123456[edit]\\n   \n",
            "585                                               +000   \n",
            "\n",
            "     University area per state  \n",
            "0                          NaN  \n",
            "1                          NaN  \n",
            "2                          NaN  \n",
            "3                          NaN  \n",
            "4                          NaN  \n",
            "..                         ...  \n",
            "581                        NaN  \n",
            "582                        NaN  \n",
            "583                        NaN  \n",
            "584                        NaN  \n",
            "585                        NaN  \n",
            "\n",
            "[586 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. A [példa](https://datasciencechalktalk.com/2019/09/28/analyzing-u-s-exports-with-plotly/), a kivitelt, exportmennyiséget ábrázolja az Amerikai Egyesült Államok térképen, államonként lebontva ezt. Készítsünk hasonló ábrákat az egyetemek abszolút, lakoság és terület szerinti eloszlásáról is. Az ábrákat exportáljuk kép formájában.\n",
        "![](https://i.ibb.co/s1zdnLY/mapplot.png)\n",
        "\n",
        "Ábra 1. [Térképen való ábrázolás](https://plotly.com/python/maps/) Plotly segítségével. [Forrás](https://datasciencechalktalk.com/2019/09/28/analyzing-u-s-exports-with-plotly/)."
      ],
      "metadata": {
        "id": "_SNDj-RrqWGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_data/egyetemek.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "universities = {}\n",
        "for line in lines:\n",
        "    # ellenőrizzük, hogy az adott sor egy államot tartalmaz-e\n",
        "    if '[edit]' in line:\n",
        "        state = line.replace('[edit]\\n', '')\n",
        "        universities[state] = {}\n",
        "    else:\n",
        "        # a sorban szereplő városok és egyetemek feldolgozása\n",
        "        city = line.split(' (')[0]\n",
        "        universities[state][city] = line.count(',') + 1\n",
        "\n",
        "# az egyetemek száma államonként\n",
        "state_universities = {}\n",
        "for state, cities in universities.items():\n",
        "    state_universities[state] = sum(cities.values())\n",
        "\n",
        "# a legtöbb egyetemmel rendelkező városok és államok meghatározása\n",
        "most_universities_city = max((city, count) for state in universities for city, count in universities[state].items())\n",
        "most_universities_state = max(state_universities.items(), key=lambda x: x[1])\n",
        "\n",
        "print(\"Egyetemek száma államonként:\\n\", state_universities)\n",
        "print(\"Egyetemek száma városonként és államonként:\\n\", universities)\n",
        "print(\"A legtöbb egyetemmel rendelkező város: {} ({})\".format(most_universities_city[0], most_universities_city[1]))\n",
        "print(\"A legtöbb egyetemmel rendelkező állam: {} ({})\".format(most_universities_state[0], most_universities_state[1]))\n"
      ],
      "metadata": {
        "id": "sKVmK4YkqnPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242bbab1-f247-43ec-8154-01aa00018492"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Egyetemek száma államonként:\n",
            " {'Alabama': 10, 'Alaska': 1, 'Arizona': 3, 'Arkansas': 11, 'California': 57, 'Colorado': 10, 'Connecticut': 14, 'Delaware': 2, 'Florida': 18, 'Georgia': 21, 'Hawaii': 1, 'Idaho': 3, 'Illinois': 10, 'Indiana': 14, 'Iowa': 15, 'Kansas': 8, 'Kentucky': 13, 'Louisiana': 9, 'Maine': 11, 'Maryland': 13, 'Massachusetts': 47, 'Michigan': 23, 'Minnesota': 27, 'Mississippi': 5, 'Missouri': 12, 'Montana': 3, 'Nebraska': 7, 'Nevada': 4, 'New Hampshire': 8, 'New Jersey': 16, 'New Mexico': 5, 'New York': 65, 'North Carolina': 27, 'North Dakota': 2, 'Ohio': 23, 'Oklahoma': 12, 'Oregon': 13, 'Pennsylvania': 59, 'Rhode Island': 9, 'South Carolina': 21, 'South Dakota': 4, 'Tennessee': 28, 'Texas': 32, 'Utah': 6, 'Vermont': 7, 'Virginia': 25, 'Washington': 6, 'West Virginia': 9, 'Wisconsin': 16, 'Wyoming': 1, '123456': 1}\n",
            "Egyetemek száma városonként és államonként:\n",
            " {'Alabama': {'Auburn': 1, 'Florence': 1, 'Jacksonville': 1, 'Livingston': 1, 'Montevallo': 1, 'Troy': 1, 'Tuscaloosa': 3, 'Tuskegee': 1}, 'Alaska': {'Fairbanks': 1}, 'Arizona': {'Flagstaff': 1, 'Tempe': 1, 'Tucson': 1}, 'Arkansas': {'Arkadelphia': 2, 'Conway': 3, 'Fayetteville': 1, 'Jonesboro': 1, 'Magnolia': 1, 'Monticello': 1, 'Russellville': 1, 'Searcy': 1}, 'California': {'Angwin': 1, 'Arcata': 1, 'Berkeley': 2, 'Chico': 2, 'Claremont': 7, 'Cotati': 2, 'Davis': 2, 'Irvine': 2, 'Isla Vista': 2, 'University Park, Los Angeles': 2, 'Merced': 2, 'Orange': 1, 'Palo Alto': 1, 'Pomona': 2, 'Redlands': 1, 'Riverside': 4, 'Sacramento': 2, 'University District, San Bernardino': 4, 'San Diego': 3, 'San Luis Obispo': 1, 'Santa Barbara': 5, 'Santa Cruz': 2, 'Turlock': 2, 'Westwood, Los Angeles': 3, 'Whittier': 1}, 'Colorado': {'Alamosa': 1, 'Boulder': 1, 'Durango': 1, 'Fort Collins': 1, 'Golden': 1, 'Grand Junction': 1, 'Greeley': 1, 'Gunnison': 1, 'Pueblo, Colorado': 2}, 'Connecticut': {'Fairfield': 2, 'Middletown': 1, 'New Britain': 1, 'New Haven': 5, 'New London': 3, 'Storrs': 1, 'Willimantic': 1}, 'Delaware': {'Dover': 1, 'Newark': 1}, 'Florida': {'Ave Maria': 1, 'Boca Raton': 1, 'Coral Gables': 1, 'DeLand': 1, 'Estero': 1, 'Gainesville': 2, 'Orlando': 1, 'Sarasota': 5, 'St. Augustine': 1, 'St. Leo': 1, 'Tallahassee': 2, 'Tampa': 1}, 'Georgia': {'Albany': 1, 'Athens': 1, 'Atlanta': 3, 'Carrollton': 1, 'Demorest': 1, 'Fort Valley': 1, 'Kennesaw': 1, 'Milledgeville': 1, 'Mount Vernon': 1, 'Oxford': 1, 'Rome': 2, 'Savannah': 3, 'Statesboro': 1, 'Valdosta': 1, 'Waleska': 1, 'Young Harris': 1}, 'Hawaii': {'Manoa': 1}, 'Idaho': {'Moscow': 1, 'Pocatello': 1, 'Rexburg': 1}, 'Illinois': {'Carbondale': 1, 'Champaign–Urbana': 1, 'Charleston': 1, 'DeKalb': 1, 'Edwardsville': 1, 'Evanston': 1, 'Lebanon': 1, 'Macomb': 1, 'Normal': 1, 'Peoria': 1}, 'Indiana': {'Bloomington': 1, 'Crawfordsville': 1, 'Greencastle': 1, 'Hanover': 1, 'Marion': 1, 'Muncie': 1, 'Oakland City': 1, 'Richmond': 1, 'South Bend': 1, 'Terre Haute': 2, 'Upland': 1, 'Valparaiso': 1, 'West Lafayette': 1}, 'Iowa': {'Ames': 1, 'Cedar Falls': 1, 'Cedar Rapids, Iowa': 2, 'Decorah': 1, 'Fayette': 1, 'Grinnell': 1, 'Iowa City': 1, 'Lamoni': 1, 'Mount Vernon,': 2, 'Orange City': 1, 'Sioux Center': 1, 'Storm Lake': 1, 'Waverly': 1}, 'Kansas': {'Baldwin City': 1, 'Emporia': 1, 'Hays': 1, 'Lawrence': 2, 'Manhattan': 2, 'Pittsburg': 1}, 'Kentucky': {'Bowling Green': 1, 'Columbia': 1, 'Georgetown': 1, 'Highland Heights': 1, 'Lexington': 2, 'Louisville': 1, 'Morehead': 1, 'Murray': 1, 'Richmond': 1, 'Williamsburg': 1, 'Wilmore': 2}, 'Louisiana': {'Baton Rouge': 2, 'Grambling': 1, 'Hammond': 1, 'Lafayette': 1, 'Monroe': 1, 'Natchitoches': 1, 'Ruston': 1, 'Thibodaux': 1}, 'Maine': {'Augusta': 1, 'Bar Harbor': 1, 'Brunswick': 1, 'Farmington': 1, 'Fort Kent': 1, 'Gorham': 1, 'Lewiston, Maine': 2, 'Orono': 1, 'Waterville': 2}, 'Maryland': {'Annapolis': 2, 'Chestertown': 1, 'College Park': 2, 'Cumberland': 1, 'Emmitsburg': 1, 'Frostburg': 1, 'Princess Anne': 1, 'Towson': 2, 'Salisbury': 1, 'Westminster': 1}, 'Massachusetts': {'Boston': 13, 'Bridgewater': 1, 'Cambridge': 4, 'Chestnut Hill': 1, 'The Colleges of Worcester Consortium:\\n': 1, 'Dudley': 1, 'North Grafton': 1, 'Paxton': 1, 'Worcester': 9, 'The Five College Region of Western Massachusetts:\\n': 1, 'Amherst': 3, 'Northampton': 1, 'South Hadley': 1, 'Fitchburg': 1, 'North Adams': 1, 'Springfield': 3, 'Waltham': 2, 'Williamstown': 1, 'Framingham': 1}, 'Michigan': {'Adrian': 2, 'Albion': 1, 'Allendale': 1, 'Alma': 1, 'Ann Arbor': 1, 'Berrien Springs': 1, 'Big Rapids': 1, 'East Lansing': 1, 'Flint': 2, 'Hillsdale': 1, 'Houghton': 1, 'Kalamazoo': 2, 'Marquette': 1, 'Midland': 1, 'Mount Pleasant': 1, 'Olivet': 1, 'Saginaw': 1, 'Sault Ste. Marie': 1, 'Spring Arbor': 1, 'Ypsilanti': 1}, 'Minnesota': {'Bemidji': 1, 'Crookston': 1, 'Duluth': 5, 'Faribault, South Central College\\n': 2, 'Mankato': 3, 'Marshall': 1, 'Moorhead': 3, 'Morris': 1, 'Northfield': 2, 'North Mankato, South Central College\\n': 2, 'St. Cloud': 2, 'St. Joseph': 1, 'St. Peter': 1, 'Winona': 2}, 'Mississippi': {'Cleveland': 1, 'Hattiesburg': 1, 'Itta Bena': 1, 'Oxford': 1, 'Starkville': 1}, 'Missouri': {'Bolivar': 1, 'Cape Girardeau': 1, 'Columbia': 3, 'Fayette': 1, 'Fulton': 1, 'Kirksville': 2, 'Maryville': 1, 'Rolla': 1, 'Warrensburg': 1}, 'Montana': {'Bozeman': 1, 'Dillon': 1, 'Missoula': 1}, 'Nebraska': {'Chadron': 1, 'Crete': 1, 'Kearney': 1, 'Lincoln': 1, 'Peru': 1, 'Seward': 1, 'Wayne': 1}, 'Nevada': {'Las Vegas': 2, 'Reno': 2}, 'New Hampshire': {'New London, New Hampshire': 2, 'Durham': 1, 'Hanover': 1, 'Henniker': 1, 'Keene': 1, 'Plymouth': 1, 'Rindge': 1}, 'New Jersey': {'Ewing': 2, 'Jersey City': 2, 'Glassboro': 1, 'Hoboken': 1, 'Madison': 3, 'Newark': 3, 'New Brunswick': 1, 'Princeton': 1, 'Union': 1, 'West Long Branch': 1}, 'New Mexico': {'Hobbs': 1, 'Las Cruces': 1, 'Las Vegas': 1, 'Portales': 1, 'Silver City': 1}, 'New York': {'Alfred': 2, 'Albany': 10, 'Aurora': 1, 'Binghamton': 1, 'Brockport': 1, 'Buffalo': 1, 'Canton': 2, 'Clinton': 1, 'Cobleskill': 1, 'Delhi': 1, 'Fredonia': 1, 'Geneseo': 1, 'Geneva': 1, 'Hamilton': 1, 'Ithaca': 2, 'Morningside Heights, Manhattan': 8, 'New Paltz': 1, 'Oneonta': 2, 'Oswego': 1, 'Plattsburgh': 1, 'Potsdam': 2, 'Poughkeepsie': 2, 'Purchase': 2, 'Rochester': 8, 'Saratoga Springs': 1, 'Seneca Falls': 1, 'Stony Brook': 1, 'Syracuse': 3, 'Tivoli': 1, 'Troy': 3, 'West Point': 1}, 'North Carolina': {'Banner Elk': 1, 'Boiling Springs': 1, 'Boone': 1, 'Buies Creek': 1, 'Chapel Hill': 1, 'Cullowhee': 1, 'Davidson': 1, 'Durham': 2, 'Elon': 1, 'Greensboro': 5, 'Greenville': 1, 'Hickory': 1, 'Mars Hill': 1, 'Mount Olive': 1, 'Pembroke': 1, 'Wilmington, North Carolina': 2, 'Wingate': 1, 'Winston-Salem': 4}, 'North Dakota': {'Fargo': 1, 'Grand Forks': 1}, 'Ohio': {'Ada': 1, 'Alliance': 1, 'Ashland': 1, 'Athens': 1, 'Berea': 1, 'Bluffton': 1, 'Bowling Green': 1, 'Cedarville': 1, 'Columbus': 1, 'Delaware': 1, 'Fairborn': 1, 'Findlay': 1, 'Gambier': 1, 'Granville': 1, 'Hiram': 1, 'Kent': 1, 'Nelsonville': 1, 'New Concord': 1, 'Oberlin': 1, 'Oxford': 1, 'Rio Grande': 1, 'Wilberforce': 2}, 'Oklahoma': {'Ada': 1, 'Alva': 1, 'Durant': 1, 'Edmond': 2, 'Goodwell': 1, 'Langston': 1, 'Norman': 1, 'Stillwater': 1, 'Tahlequah': 1, 'Tulsa': 1, 'Weatherford': 1}, 'Oregon': {'Ashland': 1, 'Corvallis': 1, 'Eugene': 3, 'Forest Grove': 1, 'Klamath Falls': 2, 'La Grande': 1, 'Marylhurst': 1, 'McMinnville': 1, 'Monmouth': 1, 'Newberg': 1}, 'Pennsylvania': {'Altoona': 1, 'Annville': 1, 'Bethlehem': 2, 'Bloomsburg': 1, 'Bradford': 1, 'California': 1, 'Carlisle': 1, 'Cecil B. Moore, Philadelphia, also known as \"Templetown\"': 3, 'Clarion': 1, 'Collegeville': 1, 'Cresson': 1, 'East Stroudsburg': 1, 'Edinboro': 1, 'Erie': 3, 'Gettysburg': 1, 'Greensburg': 2, 'Grove City': 1, 'Huntingdon': 1, 'Indiana': 1, 'Johnstown': 1, 'Kutztown': 1, 'Lancaster': 1, 'Lewisburg': 1, 'Lock Haven': 1, 'Loretto': 1, 'Mansfield': 1, 'Meadville': 1, 'Mont Alto': 1, 'Millersville': 1, 'New Wilmington': 1, 'North East': 1, 'University City, Philadelphia': 4, 'Oakland, Pittsburgh': 4, 'Reading': 3, 'Selinsgrove': 1, 'Shippensburg': 1, 'Slippery Rock': 1, 'State College': 1, 'Villanova': 1, 'Waynesburg': 1, 'West Chester': 1, 'Wilkes-Barre': 2, 'Williamsport': 2}, 'Rhode Island': {'Kingston': 1, 'Providence': 8}, 'South Carolina': {'Central': 1, 'Charleston': 3, 'Clemson': 1, 'Clinton': 1, 'Columbia': 1, 'Due West': 1, 'Florence': 1, 'Greenwood': 1, 'Orangeburg': 2, 'Rock Hill': 1, 'Spartanburg': 8}, 'South Dakota': {'Brookings': 1, 'Madison': 1, 'Spearfish': 1, 'Vermillion': 1}, 'Tennessee': {'Chattanooga': 1, 'Collegedale': 1, 'Cookeville': 1, 'Harrogate': 1, 'Henderson': 1, 'Johnson City': 1, 'Knoxville': 1, 'Martin': 1, 'McKenzie': 1, 'Memphis': 10, 'Murfreesboro': 1, 'Nashville': 7, 'Sewanee': 1}, 'Texas': {'Abilene': 3, 'Alpine': 1, 'Austin': 3, 'Beaumont': 1, 'Canyon': 1, 'College Station': 1, 'Commerce': 1, 'Dallas': 1, 'Denton': 2, 'Fort Worth': 2, 'Georgetown': 1, 'Huntsville': 1, 'Houston': 4, 'Keene': 1, 'Kingsville': 1, 'Lubbock': 2, 'Nacogdoches': 1, 'Plainview': 1, 'Prairie View': 1, 'San Marcos': 1, 'Stephenville': 1, 'Waco': 1}, 'Utah': {'Cedar City': 1, 'Logan': 1, 'Provo': 1, 'Orem': 1, 'Salt Lake City': 1, 'Ephraim': 1}, 'Vermont': {'Burlington': 2, 'Castleton': 1, 'Johnson': 1, 'Lyndonville': 1, 'Middlebury': 1, 'Northfield': 1}, 'Virginia': {'Blacksburg': 1, 'Bridgewater': 1, 'Charlottesville': 1, 'Farmville': 2, 'Fredericksburg': 1, 'Harrisonburg': 2, 'Lexington': 2, 'Lynchburg': 4, 'Radford': 1, 'Williamsburg': 1, 'Wise': 1, 'Chesapeake': 8}, 'Washington': {'Bellingham': 1, 'Cheney': 1, 'Ellensburg': 1, 'Pullman': 1, 'University District, Seattle': 2}, 'West Virginia': {'Athens': 1, 'Buckhannon': 1, 'Fairmont': 1, 'Glenville': 1, 'Huntington': 1, 'Montgomery': 1, 'Morgantown': 1, 'Shepherdstown': 1, 'West Liberty': 1}, 'Wisconsin': {'Appleton': 1, 'Eau Claire': 1, 'Green Bay': 1, 'La Crosse': 3, 'Madison': 1, 'Menomonie': 1, 'Milwaukee': 2, 'Oshkosh': 1, 'Platteville': 1, 'River Falls': 1, 'Stevens Point': 1, 'Waukesha': 1, 'Whitewater': 1}, 'Wyoming': {'Laramie': 1}, '123456': {'+000': 1}}\n",
            "A legtöbb egyetemmel rendelkező város: Ypsilanti (1)\n",
            "A legtöbb egyetemmel rendelkező állam: New York (65)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Számoljuk ki, hány egyetem van városonként, majd összesítve államonként. Ehhez az `egyetemek.txt` fájlban miután megkapunk egy várost, az utána következő kerek zárójelek között megszámoljuk, hány vesszővel elválasztott karakterlánc található. \n",
        "Pl. a következő sorban:\t`Claremont (Claremont McKenna College, Pomona College, Harvey Mudd College, Scripps College, Pitzer College, Keck Graduate Institute, Claremont Graduate University)[5]` -> 6 vessző van a kerek zárójelek között, tehát 7 egyetem van a városban.    \n",
        "Melyik államban és melyik városban van a legtöbb egyetem?"
      ],
      "metadata": {
        "id": "pKZXgALRqard"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_town(item):\n",
        "  return item[:item.find('(') - 1]\n",
        "def clean_state(item):\n",
        "  return item[:item.find('[')]\n",
        "def what_univers(item):\n",
        "  return len(item[item.find('(') - 1:].split(','))\n",
        "\n",
        "df1['NumberUniv'] = df1.Town.apply(what_univers)\n",
        "df1['Town'] = df1.Town.apply(clean_town)\n",
        "df1['State'] = df1.State.apply(clean_state)\n",
        "df1"
      ],
      "metadata": {
        "id": "5tULBhUJqnzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "by_state = df1.groupby(['State'])\n",
        "maxi = by_state.NumberUniv.sum().max()\n",
        "mini = by_state.NumberUniv.sum().min()\n",
        "print(maxi,mini)\n",
        "\n",
        "by_town = df1.groupby(['Town'])\n",
        "maxi = by_town.NumberUniv.sum().max()\n",
        "mini = by_town.NumberUniv.sum().min()\n",
        "print(maxi,mini)"
      ],
      "metadata": {
        "id": "50ghUse__daY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}